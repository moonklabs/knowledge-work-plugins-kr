---
description: 데이터셋의 형태, 품질, 패턴을 프로파일링하고 탐색
argument-hint: "<테이블 또는 파일>"
---

# /explore-data - 데이터셋 프로파일링 및 탐색

> 익숙하지 않은 플레이스홀더가 있거나 연결된 도구를 확인해야 하는 경우 [CONNECTORS.md](../CONNECTORS.md)를 참조하십시오.

테이블 또는 업로드된 파일에 대한 종합적인 데이터 프로파일을 생성합니다. 분석에 들어가기 전에 데이터의 형태, 품질, 패턴을 파악합니다.

## 사용법

```
/explore-data <table_name or file>
```

## 워크플로우

### 1. 데이터 접근

**데이터 웨어하우스 MCP 서버가 연결된 경우:**

1. 테이블 이름을 확인합니다 (스키마 접두사 처리, 모호한 경우 일치 항목 제안)
2. 테이블 메타데이터를 쿼리합니다: 컬럼명, 유형, 가용한 경우 설명
3. 실제 데이터에 대해 프로파일링 쿼리를 실행합니다

**파일이 제공된 경우 (CSV, Excel, Parquet, JSON):**

1. 파일을 읽어 작업 데이터셋에 로드합니다
2. 데이터에서 컬럼 유형을 추론합니다

**둘 다 없는 경우:**

1. 사용자에게 테이블 이름(웨어하우스 연결 상태) 또는 파일 업로드를 요청합니다
2. 테이블 스키마를 설명해 주면 실행할 프로파일링 쿼리를 안내합니다

### 2. 데이터 프로파일 생성

다음 프로파일링 검사를 실행합니다:

**테이블 수준 지표:**
- 전체 행 수
- 컬럼 수 및 유형 분포
- 대략적인 테이블 크기 (메타데이터에서 사용 가능한 경우)
- 날짜 범위 (날짜 컬럼의 최솟값/최댓값)

**각 컬럼의 컬럼 수준 지표:**
- 데이터 유형 (예상 유형과 일치 여부)
- Null 수 및 null 비율 (%)
- 고유값 수 및 카디널리티 (고유값 / 전체)
- 숫자형 컬럼: 최솟값, 최댓값, 평균, 중앙값, 표준편차, 백분위수 (p25, p50, p75, p95, p99)
- 문자형 컬럼: 최소/최대 길이, 가장 빈번한 값 (상위 10개), 빈 문자열 수
- 날짜/타임스탬프 컬럼: 최솟값, 최댓값, 기간별 분포
- 불리언 컬럼: true/false/null 분포

**깔끔한 요약 테이블로 프로파일을 제시합니다**, 컬럼 유형별로 그룹화합니다 (차원, 지표, 날짜, ID).

### 3. 데이터 품질 문제 식별

잠재적 문제를 플래그합니다:

- **높은 null 비율**: 5% 이상 null인 컬럼 (경고), 20% 이상 null (알림)
- **예상 외 낮은 카디널리티**: 높은 카디널리티여야 하는데 그렇지 않은 컬럼 (예: `user_id`가 50개의 고유값만 가짐)
- **예상 외 높은 카디널리티**: 범주형이어야 하지만 고유값이 너무 많은 컬럼
- **의심스러운 값**: 양수만 예상되는 곳의 음수, 과거 데이터의 미래 날짜, 명백한 플레이스홀더 값 (예: "N/A", "TBD", "test", "999999")
- **중복 탐지**: 자연 키가 있는지, 중복이 있는지 확인
- **분포 편향**: 평균에 영향을 줄 수 있는 극단적으로 편향된 숫자 분포
- **인코딩 문제**: 범주형 필드의 대소문자 혼합, 후행 공백, 일관되지 않은 형식

### 4. 관심 있는 차원 및 지표 제안

컬럼 프로파일을 기반으로 다음을 추천합니다:

- **최적 차원 컬럼**: 적절한 카디널리티(3-50개 값)를 가진 범주형 컬럼으로 데이터 분할 기준
- **핵심 지표 컬럼**: 의미 있는 분포를 가진 숫자형 컬럼으로 측정 기준
- **시간 컬럼**: 추세 분석에 적합한 컬럼
- **자연 그룹핑**: 데이터에서 드러나는 자연 그룹핑 또는 계층 구조
- **잠재적 조인 키**: 다른 테이블에 연결되는 ID 컬럼, 외래 키

### 5. 후속 분석 추천

다음에 실행할 수 있는 3-5개의 구체적인 분석을 제안합니다:

- "[time_column]별, [dimension]으로 그룹화한 [metric] 추세 분석"
- "이상치를 이해하기 위한 [skewed_column] 분포 심층 분석"
- "[problematic_column]에 대한 데이터 품질 조사"
- "[metric_a]와 [metric_b] 간의 상관관계 분석"
- "[date_column]과 [status_column]을 활용한 코호트 분석"

## 출력 형식

```
## 데이터 프로파일: [table_name]

### 개요
- 행 수: 2,340,891
- 컬럼 수: 23 (8개 차원, 6개 지표, 4개 날짜, 5개 ID)
- 날짜 범위: 2021-03-15 ~ 2024-01-22

### 컬럼 상세 내역
[요약 테이블]

### 데이터 품질 문제
[심각도가 포함된 플래그 지정된 문제들]

### 권장 탐색 분석
[번호가 매겨진 제안된 후속 분석 목록]
```

## 팁

- 매우 큰 테이블(1억 행 이상)의 경우 프로파일링 쿼리는 기본적으로 샘플링을 사용합니다 -- 정확한 수치가 필요하면 언급하십시오
- 처음 접하는 데이터셋을 탐색하는 경우, 이 커맨드로 구체적인 쿼리를 작성하기 전에 전체적인 현황을 파악할 수 있습니다
- 품질 플래그는 휴리스틱(heuristic)입니다 -- 모든 플래그가 실제 문제는 아니지만, 각각 한 번쯤 확인할 가치가 있습니다
